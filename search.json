[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "julia\n\n\n\n\n\n\n\n\n\n\n\nAug 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\n\n\nJun 21, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2020\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a main contributor to the Makie plotting ecosystem for which I wrote the layouting system. I also maintain a couple of Julia packages such as the data wrangling macro tool Chain.jl, the tweening library Animations.jl and the regex helper ReadableRegex.jl."
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "",
    "text": "DataFrameMacros.jl is a Julia package that makes it easier to manipulate DataFrames, by rewriting code into source-function-sink expressions that conform to DataFrames.jl’s more verbose mini-language. In version v0.2 (and v0.2.1) I have added a couple new features that are powerful, but not immediately obvious. This post takes a closer look at the new functionality.\nThe new features are multi-column specifiers, shortcut strings for renaming and subset transformations."
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#multi-column-specifiers",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#multi-column-specifiers",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Multi-column specifiers",
    "text": "Multi-column specifiers\nSo far, DataFrameMacros.jl only supported statements with single-column specifiers. For example, @select(df, :x + 1) or @combine(df, $column_variable * $2). The expressions :x, $column_variable and $2 all refer to one column each. The underlying source-function-sink expression that DataFrameMacros.jl created was therefore always of the form source => function => sink. For many tasks this is perfectly sufficient, but other times one wants to execute the same function over a set of similar or related columns.\nDataFrames.jl has a neat way to run the same function on a set of columns. This is done by using the .=> operator, to broadcast over a set or sets of columns and create an array of source => function => sink expressions. For example, you could compute the sum for each column in a DataFrame with transform(df, names(df, All()) .=> sum), or in the recent v1.3 release even with transform(df, All() .=> sum).\nNow, the trick that DataFrameMacros.jl v0.2.1 uses is to change the underlying representation from source => function => sink to source(s) .=> function(s) .=> sink(s). This doesn’t break the existing functionality, because scalars in Julia broadcast just fine, so it’s no problem to say something like combine(df, :x .=> sum .=> \"y\") - even though broadcasting doesn’t add anything if only scalars participate.\nWhere it gets interesting is when collections of columns are used. With the change to source(s) .=> function(s) .=> sink(s) you are now free to use column expressions that refer to multiple columns. The only restriction is that the shapes of source(s), function(s) and sink(s) have to be compatible for broadcasting.\nThere are multiple ways in which you can reference multiple columns at once, and they are closely related to what x can be in the function names(df, x). For example, All(), Between(x, y) and Not(args...) are now recognized directly as multi-column specifiers by DataFrameMacros, without having to mark them with the usual $ sign. Then you can use any Type T marked by $, which selects all columns whose elements are subtypes of T, for example $Real or $String. You can use a regex that selects all columns with matching names, for example $(r\"a\") for any column with the letter a. Of course it’s also possible to just pass an array of column names, for example $[\"a\", \"b\"].\nHere are a few practical examples:\n\nusing DataFrameMacros\nusing DataFrames\n\ndf = DataFrame(\n    name = [\"alice\", \"bob\", \"charlie\"],\n    age = [20, 31, 42],\n    country = [\"andorra\", \"brazil\", \"croatia\"],\n    salary = [9999, 6666, 3333],\n)\n\n\n3 rows × 4 columnsnameagecountrysalaryStringInt64StringInt641alice20andorra99992bob31brazil66663charlie42croatia3333\n\n\nWe can transform both String columns at once and both Int columns at once, by using the Type multi-column specifier.\n\n@select df begin\n    uppercasefirst($String)\n    Float64($Int)\nend\n\n\n3 rows × 4 columnsname_uppercasefirstcountry_uppercasefirstage_Float64salary_Float64StringStringFloat64Float641AliceAndorra20.09999.02BobBrazil31.06666.03CharlieCroatia42.03333.0\n\n\nWe can try out the All() specifier by reversing the element order of each column. We need the @c flag so reverse acts on each column vector and not each column element. This works the same way with the Between and Not selectors.\n\n@select df @c reverse(All())\n\n\n3 rows × 4 columnsname_reverseage_reversecountry_reversesalary_reverseStringInt64StringInt641charlie42croatia33332bob31brazil66663alice20andorra9999\n\n\nWe can combine multi-column specifiers with single-column specifiers, they can always broadcast together because scalars work together with any shape. For example, let’s say we have a column with tax rates and four columns with quarterly gains and we want to compute the quarterly taxes.\n\ndf = DataFrame(\n    year = [2019, 2020, 2021],\n    tax_rate = [0.19, 0.20, 0.21],\n    income_q1 = [2000, 3000, 4000],\n    income_q2 = [2100, 3100, 4100],\n    income_q3 = [2200, 3200, 4200],\n    income_q4 = [2300, 3300, 4300],\n)\n\n\n3 rows × 6 columnsyeartax_rateincome_q1income_q2income_q3income_q4Int64Float64Int64Int64Int64Int64120190.192000210022002300220200.23000310032003300320210.214000410042004300\n\n\nThen we can simply multiply the tax rate with the four income columns at once, which we select with the Between selector.\n\n@select(df, :tax_rate * Between(3, 6))\n\n\n3 rows × 4 columnstax_rate_income_q1_*tax_rate_income_q2_*tax_rate_income_q3_*tax_rate_income_q4_*Float64Float64Float64Float641380.0399.0418.0437.02600.0620.0640.0660.03840.0861.0882.0903.0\n\n\nAnother option to select the columns would be to use a regex. We have to mark it with $ so that DataFrameMacros knows to treat it as a column specifier.\n\n@select(df, :tax_rate * $(r\"income\"))\n\n\n3 rows × 4 columnstax_rate_income_q1_*tax_rate_income_q2_*tax_rate_income_q3_*tax_rate_income_q4_*Float64Float64Float64Float641380.0399.0418.0437.02600.0620.0640.0660.03840.0861.0882.0903.0\n\n\nNow one issue is that the resulting column names are very ugly. We could specify the new names directly as a vector. Remember that the expression is source(s) .=> function(s) .=> sink(s) so we can also broadcast a vector of sinks. The string \"taxes_q1\" will be the sink associated with the first element from the regex selector, and so on.\n\n@select(df,\n    [\"taxes_q1\", \"taxes_q2\", \"taxes_q3\", \"taxes_q4\"] = :tax_rate * $(r\"income\"))\n\n\n3 rows × 4 columnstaxes_q1taxes_q2taxes_q3taxes_q4Float64Float64Float64Float641380.0399.0418.0437.02600.0620.0640.0660.03840.0861.0882.0903.0\n\n\nBut writing out strings like that is error prone, especially if the order of columns can change. So it would be better to transform the original column names. DataFrames allows to use anonymous functions for this, the input for the function is a vector with all column names used in the expression. We can split off the \"q1\" part from the second column in each expression (the income column) and prefix with \"taxes_\":\n\n@select(df, (names -> \"taxes_\" * split(names[2], \"_\")[2]) = :tax_rate * $(r\"income\"))\n\n\n3 rows × 4 columnstaxes_q1taxes_q2taxes_q3taxes_q4Float64Float64Float64Float641380.0399.0418.0437.02600.0620.0640.0660.03840.0861.0882.0903.0\n\n\n\nBroadcasting with more than one dimension\nYou are not technically limited to broadcasting one vector of columns with scalar columns, you can even evaluate two- or higher-dimensional grids of column combinations if you like. For example, if you had two different tax rates and three income categories, you could compute all six tax columns with one expression. Here we extract the income columns first so we can make them into a row-vector with permutedims, which will form a 2D grid when broadcasted together with the column vector with the two tax columns.\n\ndf = DataFrame(\n    year = [2019, 2020, 2021],\n    tax_a = [0.19, 0.20, 0.21],\n    tax_b = [0.22, 0.23, 0.24],\n    income_a = [2000, 3000, 4000],\n    income_b = [2100, 3100, 4100],\n    income_c = [2200, 3200, 4200],\n)\n\nincome_cols = permutedims(names(df, r\"income\"))\n\n@select(df, $(r\"tax\") * $income_cols)\n\n\n3 rows × 6 columns (omitted printing of 1 columns)tax_a_income_a_*tax_b_income_a_*tax_a_income_b_*tax_b_income_b_*tax_a_income_c_*Float64Float64Float64Float64Float641380.0440.0399.0462.0418.02600.0690.0620.0713.0640.03840.0960.0861.0984.0882.0\n\n\nThe column names are again not ideal, which brings us to another new feature."
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#shortcut-strings-for-renaming",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#shortcut-strings-for-renaming",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Shortcut strings for renaming",
    "text": "Shortcut strings for renaming\nOften, we want to give new columns names that are just simple combinations of column names used to compute them. In the last example, a better name than tax_a_income_a_* could be tax_a_on_income_b.\nIf DataFrameMacros encounters a string literal as the sink which contains \"{}\", \"{1}\" or \"{2}\" and up, it translates this into a renaming function that pastes the input column names at the respective locations. Here’s the last example again with such a shortcut string:\n\n@select(df, \"{1}_on_{2}\" = $(r\"tax\") * $income_cols)\n\n\n3 rows × 6 columns (omitted printing of 1 columns)tax_a_on_income_atax_b_on_income_atax_a_on_income_btax_b_on_income_btax_a_on_income_cFloat64Float64Float64Float64Float641380.0440.0399.0462.0418.02600.0690.0620.0713.0640.03840.0960.0861.0984.0882.0"
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#subset-transformations",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#subset-transformations",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Subset transformations",
    "text": "Subset transformations\nThe third new feature goes hand in hand with a new addition in DataFrames v1.3. Now you can call transform! or select! on the view returned by subset(df, some_subset_expression, view = true), and this will mutate the underlying DataFrame only in the selected rows. If new columns are added, all rows outside the subset are filled with missing values.\nIn base DataFrames, you need to first create a subset view, then mutate it, then continue on with the original DataFrame. Here’s the DataFrame we start with\n\ndf = DataFrame(x = 1:4, y = 5:8)\n\n\n4 rows × 2 columnsxyInt64Int64115226337448\n\n\nNow we subset some rows and increment the y values by 10 there. We also create new z values:\n\nsubset_view = subset(df, :x => ByRow(>=(3)), view = true)\ntransform!(\n    subset_view,\n    :y => ByRow(x -> x + 10) => :y,\n    :x => (x -> x * 3) => :z\n)\ndf\n\n\n4 rows × 3 columnsxyzInt64Int64Int64?115missing226missing33179441812\n\n\nIn DataFrameMacros v0.2, you can now use a more convenient syntax that plays well with Chain.jl or other piping mechanisms, where you only want to use functions that return the DataFrame you work with, not a subset view. You can simply pass a @subset expression to @transform! or @select! after the DataFrame argument. This @subset expression doesn’t take its own DataFrame argument as usual, that’s implied to be the DataFrame that is being transformed. The returned object after mutating the selected rows is the original DataFrame. You can see how much more concise the same operation becomes:\n\ndf = DataFrame(x = 1:4, y = 5:8)\n@transform!(df, @subset(:x >= 3), :y = :y + 10, :z = 3 * :x)\n\n\n4 rows × 3 columnsxyzInt64Int64Int64?115missing226missing33179441812"
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#summary",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#summary",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Summary",
    "text": "Summary\nThat concludes the overview of the three new features, multi-column specifiers, shortcut strings for renaming and subset transformations. Especially multi-column specifiers with their implicit broadcasting might need a moment to wrap your head around, but I think you’ll find them very convenient. I hope you enjoy using the new release!"
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html",
    "href": "pages/2021-06-07-macros-for-beginners/index.html",
    "title": "Julia macros for beginners",
    "section": "",
    "text": "Macros are a powerful and interesting feature of the Julia programming language, but they can also be confusing. Users coming from Python, Matlab or R have not come in contact with similar constructs before, and they require a different way of thinking about code. This article is supposed to be a simple introduction, after which you might judge better when use of macros is appropriate and how to get around some of the most common gotchas."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#what-are-macros-for",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#what-are-macros-for",
    "title": "Julia macros for beginners",
    "section": "What are macros for?",
    "text": "What are macros for?\nMacros change existing source code or generate entirely new code. They are not some kind of more powerful function that unlocks secret abilities of Julia, they are just a way to automatically write code that you could have written out by hand anyway. There’s just the question whether writing that code by hand is practical, not if it’s possible. Often, we can save users a lot of work, by hiding boilerplate code they would otherwise need to write inside our macro.\nStill, it’s good advice, especially for beginners, to think hard if macros are the right tool for the job, or if run-of-the-mill functions serve the same purpose. Often, functions are preferable because macro magic puts a cognitive burden on the user, it makes it harder to reason about what code does. Before understanding the code, they have to understand the transformation that the macro is doing, which often goes hand in hand with non-standard syntax. That is, unless they are ok with their code having unintended consequences."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#what-does-a-macro-do",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#what-does-a-macro-do",
    "title": "Julia macros for beginners",
    "section": "What does a macro do?",
    "text": "What does a macro do?\nSome of the magic of macros derives from the fact that they don’t just generate some predefined code, they rather take the code they are applied to and transform it in useful ways. Variable names are one of the fundamental mechanisms by which we make code understandable for humans. In principle, you could replace every identifier in a working piece of code with something random, and it would still work.\nprofit = revenue - costs\n# does the same thing as\nhey = whats - up\nThe computer doesn’t care about the names, only humans do. But functions run after the code has been transformed into lower-level representations, and names are lost at that point.\nFor example, in this code snippet, there is no way for the author of the function to know what the user named their variable. The function just receives a value, and as far as it is concerned, that value is named x.\n\nfunction show_value(x)\n    println(\"The value you passed is \", x)\nend\n\norange = \"sweet\"\napple = \"sour\"\n\nshow_value(orange)\nshow_value(apple)\n\nThe value you passed is sweet\nThe value you passed is sour\n\n\nAny information about what the user wrote is lost, as the function only knows “sweet” and “sour” were passed. If we want to incorporate the information contained in the variable names, we need a macro.\n\nmacro show_value(variable)\n    quote\n        println(\"The \", $(string(variable)), \" you passed is \", $(esc(variable)))\n    end\nend\n\n@show_value(orange)\n@show_value(apple)\n\nThe orange you passed is sweet\nThe apple you passed is sour\n\n\nYou probably know a macro that works very similar to this one, which is @show\n\n@show orange\n@show apple\n\nNote that it doesn’t make a difference here if we use parentheses for the macros or not. That’s a feature of Julia’s syntax which makes some macros more tidy to write. This is especially true if the macro precedes a for block or some other multi-line expression."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#how-do-macros-work",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#how-do-macros-work",
    "title": "Julia macros for beginners",
    "section": "How do macros work?",
    "text": "How do macros work?\nLet’s look at our macro in more detail. Even though it’s short, it has a few interesting aspects to it.\nFirst of all, a macro runs before any code is executed. Therefore, you never have access to any runtime values in a macro. That’s something that trips many beginners up, but is crucial to understand. All the logic in the macro has to happen only using the information you can get from the expressions that the macro is applied to.\nOne good step to understand what’s going on with an expression, is to dump it. You can use Meta.@dump for that.\nIn our case, it’s not very interesting:\n\nMeta.@dump orange\n\nSymbol orange\n\n\nAs you can see, the expression orange contains only the Symbol orange. So that is what our macro gets as input, just :orange. But, again, no runtime information about it being \"sweet\".\nInside the macro, a quote expression is constructed. A quote with source code inside returns an expression object that describes this code. The expression we return from a macro is spliced into the place where the macro call happens, as if you really had written the macro result there. That’s the reason why a macro can’t technically do more than any old Julia code.\nWe can see the code that the macro call results in by using another helper macro, @macroexpand.\n\n@macroexpand @show_value orange\n\n\nquote\n    #= In[3]:3 =#\n    Main.println(\"The \", \"orange\", \" you passed is \", orange)\nend\n\n\n\nYou can see that, ignoring linenumber and module information, the macro created a function call as if we had written\nprintln(\"The \", \"orange\", \" you passed is \", orange)\nTherefore, let’s look at where the two oranges come from.\nThe first one is \"orange\", which is a string literal. We achieved this with this expression inside the macro:\n$(string(variable))\nRemember that variable holds the Symbol :orange when the macro is called. We convert that to a string and then place that string into the quoted expression using the interpolation symbol $. This is how we can print out a sentence that references the user’s chosen variable name.\nThe other orange is just a normal variable name. It was created with the interpolation expression $(esc(variable)). The esc stands for escape and is another part of macros that is hard to understand for beginners."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#whats-escaping",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#whats-escaping",
    "title": "Julia macros for beginners",
    "section": "What’s escaping?",
    "text": "What’s escaping?\nTo explain why esc needed, let’s look at a macro that leaves it out. In this example we define the macro in a separate module (because any macro you’d put in a package would not be in the Main module either):\n\nmodule SomeModule\n    export @show_value_no_esc\n    macro show_value_no_esc(variable)\n        quote\n            println(\"The \", $(string(variable)), \" you passed is \", $variable)\n        end\n    end\nend\n\nusing .SomeModule\n\ntry\n    @show_value_no_esc(orange)\ncatch e\n    sprint(showerror, e)\nend\n\n\"UndefVarError: orange not defined\"\n\n\nThe code errors because there is no variable orange. But there should be, we interpolated it right there! Let’s look at the macro output with @macroexpand again:\n\n@macroexpand @show_value_no_esc(orange)\n\n\nquote\n    #= In[7]:5 =#\n    Main.SomeModule.println(\"The \", \"orange\", \" you passed is \", Main.SomeModule.orange)\nend\n\n\n\nOk, so the variable looked up is actually SomeModule.orange, and of course we didn’t define a variable with that name in SomeModule. The reason this happens is that macros do often need to reference values from whatever module they were defined in. For example, to add a helper function that also lives in that module to the user’s code. Any variable name used in the created expression is looked up in the macro’s parent module by default.\nThe other reason is that it is potentially dangerous to just change or create variables in user space in a macro that knows nothing about what’s going on there.\nImagine the writer of the macro and the user as two people who know nothing about each other. They only interface via the small snippet of code passed to the macro. So, obviously, the macro shouldn’t mess around with the user’s variables.\nIn theory, a macro could insert things like my_variable = nothing or empty!(some_array) in the place where it’s used. But imagine the user already has a my_variable and it happens to hold the result of a computation that ran hours. As the macro writer doesn’t know anything about the variables the user has created, all macro-created variables are by default scoped to the macro’s module to avoid conflicts.\nHere’s a short example of bad escaping, with a macro that is not really supposed to do anything:\n\nmacro change_nothing(exp)\n    e = quote\n        temp_variable = nothing # this could be some intermediate computation\n        $exp # we actually just pass the input expression back unchanged\n    end\n    esc(e) # but everything is escaped\nend\n\n@change_nothing (macro with 1 method)"
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#a-user-who-happens-to-have-a-temp-variable-calls-this-macro",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#a-user-who-happens-to-have-a-temp-variable-calls-this-macro",
    "title": "Julia macros for beginners",
    "section": "a user who happens to have a temp variable calls this macro…",
    "text": "a user who happens to have a temp variable calls this macro…\n\ntemp_variable = \"important information\"\nx = @change_nothing 1 + 1\n\n@show x\n@show temp_variable\n\nWhoops, the temp_variable was overwritten by the macro, and this can happen with badly written macros.\nBut still, in order to access the value of the user’s variable orange, we need to escape the use of that symbol in our generated expression. Escaping the variable could be summarized as saying “treat this variable like a variable the user has written themselves”.\nAs a rule of thumb, macros should only ever escape variables that they know about because they were passed to the macro. These are the variables that the user potentially wants to have changed by the macro, or at least they are aware that they could be subject to change.\nHere you can see another example, where there is both a user and a module orange:\n\nmodule AnotherModule\n    export @show_value_user_and_module\n\n    orange = \"bitter\"\n\n    macro show_value_user_and_module(variable)\n        quote\n            println(\"The \", $(string(variable)), \" you passed is \", $(esc(variable)),\n                \" and the one from the module is \", $variable)\n        end\n    end\nend\n\nusing .AnotherModule\n\n@show_value_user_and_module orange\n\nThe orange you passed is sweet and the one from the module is bitter"
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#modifying-expressions",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#modifying-expressions",
    "title": "Julia macros for beginners",
    "section": "Modifying expressions",
    "text": "Modifying expressions\nEven though we could already see some interesting macro properties, maybe you didn’t start reading this article to learn about printing users their own variable names back (even though that is a very user friendly behavior in general, and many R users like their non-standard evaluation a lot for this reason).\nUsually, you want to modify the expression you receive, or build a new one with it, to achieve some functional purpose. Sometimes, macros are used to define domain specific languages or DSLs, that allow users to specify complex things with simple, yet non-standard expressions.\nA good example for this are the formulas from StatsModels.jl, where @formula(y ~ x) is a nice shortcut to create a formula object that you could in principle build yourself without a macro, but with much more typing.\nLet’s try to write a small useful macro that transforms a real expression!\nAn issue some Julia users face once in a while, is that the fill function’s argument is executed once, and then the whole vector is filled with that result. Let’s say we want a vector of 5 three-element random vectors.\n\nrand_vec = fill(rand(3), 5)\n\n5-element Vector{Vector{Float64}}:\n [0.43332892722732175, 0.5782544597985374, 0.7018423734651809]\n [0.43332892722732175, 0.5782544597985374, 0.7018423734651809]\n [0.43332892722732175, 0.5782544597985374, 0.7018423734651809]\n [0.43332892722732175, 0.5782544597985374, 0.7018423734651809]\n [0.43332892722732175, 0.5782544597985374, 0.7018423734651809]\n\n\nAs you can see, every vector is the same, which we don’t want. A way to get our desired result is with a list comprehension:\n\nrand_vec = [rand(3) for _ in 1:5]\n\n5-element Vector{Vector{Float64}}:\n [0.8725330212586709, 0.4795816230082033, 0.9172392083002981]\n [0.9719559431191102, 0.19043032642674818, 0.08611899155355529]\n [0.7161171606001293, 0.302776139613366, 0.7718944119034991]\n [0.2002017063644278, 0.5746728692444949, 0.8964453459163226]\n [0.7202575009260345, 0.09129552321489198, 0.2932641215021371]\n\n\nThis works, but the fill syntax is so nice and short in comparison. Also it gets even worse if you are iterating multiple dimensions in nested for loops, while you can always write fill(rand(3), 3, 4, 5).\nSo can we write a macro that makes a list comprehension expression out of a call like @fill(rand(3), 5), so that the first argument is executed anew in each iteration? Let’s try it!\nThe first step is always to understand what expression you’re even trying to build. We already use two iterators here to understand how multiple are handled in the resulting expression:\n\nMeta.@dump [rand(3) for _ in 1:5, _ in 1:3]\n\nExpr\n  head: Symbol comprehension\n  args: Array{Any}((1,))\n    1: Expr\n      head: Symbol generator\n      args: Array{Any}((3,))\n        1: Expr\n          head: Symbol call\n          args: Array{Any}((2,))\n            1: Symbol rand\n            2: Int64 3\n        2: Expr\n          head: Symbol =\n          args: Array{Any}((2,))\n            1: Symbol _\n            2: Expr\n              head: Symbol call\n              args: Array{Any}((3,))\n                1: Symbol :\n                2: Int64 1\n                3: Int64 5\n        3: Expr\n          head: Symbol =\n          args: Array{Any}((2,))\n            1: Symbol _\n            2: Expr\n              head: Symbol call\n              args: Array{Any}((3,))\n                1: Symbol :\n                2: Int64 1\n                3: Int64 3\n\n\nAha, now we actually see some real expressions. Every Expr object has a head that stores what kind of expression it is, and a vector called args which contains all arguments to that expression.\nWe can see that a list comprehension is made by making an Expr where the head is :comprehension. There’s only one argument to that expression, which is a :generator expression. This one in turn is assembled of the expression being called in each iteration, and the iteration expressions _ = 1:5 and _ = 1:3.\nWe want to use the syntax @fill(rand(3), sizes...), so we need to think how we can transform those two arguments into the expression we want.\nHere, we’ll build the Expr by hand, instead of writing one big quote. Sometimes that is easier, it also depends on what you find more readable. Expressions with a lot of quoting and interpolating can be hard to understand. I usually prefer quote ... end over the equivalent :(...) just because I can parse words a bit better than parentheses.\nHere we go:\nFor each size argument, we make one of the iterator expressions that we saw in the dump above. We escape each size variable s because those are the arguments that the user will write themselves, and they need to resolve correctly in their scope later.\nThe comprehension expression then receives the first argument escaped because that expression also needs to run as-is in the user’s scope.\n\nmacro fill(exp, sizes...)\n   \n    iterator_expressions = map(sizes) do s\n        Expr(\n            :(=),\n            :_,\n            quote 1:$(esc(s)) end\n        )\n    end\n    \n    Expr(\n        :comprehension,\n        esc(exp),\n        iterator_expressions...\n    )\nend\n\n@fill (macro with 1 method)\n\n\nLet’s try it out:\n\n@fill(rand(3), 5)\n\n5-element Vector{Vector{Float64}}:\n [0.02627205349464823, 0.11533423884129146, 0.2973247165009204]\n [0.297583789394681, 0.06903570913101054, 0.45629749169344835]\n [0.0692246211970835, 0.9507456085284235, 0.7833397066448377]\n [0.13731160049441005, 0.7236868931286216, 0.9473667580650219]\n [0.5264428859698403, 0.3563184005633261, 0.11675011608509278]\n\n\nA good check if you’ve escaped correctly is to pass expressions that reference some local variables. The call will error if you’ve forgotten to escape any of them:\n\nn = 3\nk = 5\n\n@fill(rand(n), k)\n\n5-element Vector{Vector{Float64}}:\n [0.7039197395563538, 0.9816386989332266, 0.1694562488888508]\n [0.17571625986592, 0.9636575517806829, 0.018570143498500502]\n [0.20014539538594045, 0.11405234139579701, 0.8857689386671248]\n [0.6176150545544709, 0.05380364032724694, 0.8572089253093892]\n [0.4671904345271324, 0.05192318622037595, 0.5816153176748692]\n\n\nThis works fine! It should also work with more size arguments, we’ll generate only random scalars so the printout is manageable:\n\n@fill(rand(), 5, 3)\n\n5×3 Matrix{Float64}:\n 0.148051  0.0548755  0.0984375\n 0.953251  0.451733   0.414434\n 0.69841   0.964177   0.999719\n 0.174305  0.959451   0.459463\n 0.606962  0.571768   0.97671\n\n\nEven though this particular example is contrived for simplicity (we could just use rand(5, 3 of course) compare it to the alternative list comprehension syntax:\n\n[rand() for _ in 1:5, _ in 1:3]\n\n5×3 Matrix{Float64}:\n 0.765228  0.772367   0.655585\n 0.374126  0.0999815  0.979332\n 0.2307    0.25978    0.304035\n 0.015909  0.595303   0.925112\n 0.502928  0.349744   0.536903"
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#summary",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#summary",
    "title": "Julia macros for beginners",
    "section": "Summary",
    "text": "Summary\nAs you can see, macros can be a gain in syntax clarity, and they offer a powerful way to interact with the user’s source code.\nJust remember that a reader also needs to understand what’s happening. In our example, rand() is not just executed once but many times, which is non-standard behavior for something resembling a function call. This code-reasoning overhead must always be weighed against the convenience of shorter syntax.\nI hope you have learned a thing or two about macros and are encouraged to play around with them yourself. Usually, good ideas for macros only present themselves after interacting with Julia for a while, so if you are a beginner, give it time and become proficient with normal functions first."
  },
  {
    "objectID": "pages/2022-08-09-composing-macros/index.html",
    "href": "pages/2022-08-09-composing-macros/index.html",
    "title": "Composing macros inside-out with Julia",
    "section": "",
    "text": "Macros don’t compose\nOne problematic consequence of this is that macros do not really compose. For example, let’s say you have two macros that operate on function definitions and add some useful things to them.\nLet’s make one which wraps the body of a function in a timing operation. Note that I do this with an inner function as a quick-and-dirty way, because otherwise I have to deal with possibly multiple return statements from the function body.\n\nmacro functime(expr)\n    expr.head == :function || error(\"Not a function expression.\")\n    funcname = expr.args[1].args[1]\n    :(\n        function $(esc(funcname))(args...; kwargs...)\n            f = $expr\n            println(\"Started execution at $(time())\")\n            result = f(args...; kwargs...)\n            println(\"Stopped execution at $(time())\")\n            return result\n        end\n    )\nend\n\n@functime function func()\n    sleep(0.5)\n    return \"result\"\nend\n\nfunc()\n\nStarted execution at 1.661690128240269e9\nStopped execution at 1.661690128751143e9\n\n\n\"result\"\n\n\nAnd here’s one that just logs that the function is being run:\n\nmacro funclog(expr)\n    expr.head == :function || error(\"Not a function expression.\")\n    funcname = expr.args[1].args[1]\n    :(\n        function $(esc(funcname))(args...; kwargs...)\n            f = $expr\n            @info(\"Running function.\")\n            result = f(args...; kwargs...)\n            return result\n        end\n    )\nend\n\n@funclog function func2()\n    sleep(0.5)\n    return \"result\"\nend\n\nfunc2()\n\n┌ Info: Running function.\n└ @ Main In[3]:7\n\n\n\"result\"\n\n\nBut you cannot use both macros at once on a single function definition, because each macro expects an expression in form of a function definition as its argument. And putting a different macro inside means that the expression is of type :macrocall and not type :function, which our macros don’t know how to deal with.\nSo this doesn’t work:\n@functime @funclog function func3()\n    sleep(0.5)\n    return \"result\"\nend\nOf course we can use higher-order functions for what I’m showing here, but that’s not the point of the exercise, it’s to try and see if we can use macros in a layered / composed way.\n\n\nThe inside-out macro\nWhat I wanted to try here was to make the macros run from inside-out, like functions. For this, I made another small meta-macro which calls macroexpand from the inside out if it encounters multiple macros (with recursive = false because we want to keep any macros inside the main body intact throughout the transformations like usual). That means @insideout @macro1 @macro2 expr first expands @macro2 expr and then @macro1 output_expr.\n\nmacro insideout(exp)\n    function apply_macro(exp::Expr)\n        if exp isa Expr && exp.head == :macrocall\n            exp.args[3] = apply_macro(exp.args[3])\n            return macroexpand(@__MODULE__, exp, recursive = false)\n        else\n            return exp\n        end\n    end\n    \n    apply_macro(exp)\nend\n\n@insideout (macro with 1 method)\n\n\nThis means one can now compose macros:\n\n@insideout @functime @funclog function func3()\n    sleep(0.5)\n    return \"result\"\nend\n\nfunc3()\n\nStarted execution at 1.661690130139917e9\nStopped execution at 1.661690130642331e9\n\n\n┌ Info: Running function.\n└ @ Main In[3]:7\n\n\n\"result\"\n\n\nThese examples are contrived but I wonder if someone can come up with a more interesting use-case for the technique.\nAt least it’s fun trying @insideout with some of the usual macros to modify what happens in an interesting way:\nFor example, using @show on @show:\n\n@show @show 1 + 2\n\n1 + 2 = 3\n#= In[6]:1 =# @show(1 + 2) = 3\n\n\n3\n\n\nvs. with the inside-out mode, which turns @show into some weird kind of macroexpand-and-run:\n\n@insideout @show @show 1 + 2\n\n1 + 2 = 3\nbegin\n    Base.println(\"1 + 2 = \", Base.repr(begin\n                #= show.jl:1047 =#\n                local var\"#208#value\" = 1 + 2\n            end))\n    var\"#208#value\"\nend = 3\n\n\n3"
  },
  {
    "objectID": "pages/2021-06-20-football-data-analysis/index.html",
    "href": "pages/2021-06-20-football-data-analysis/index.html",
    "title": "Analyzing international football results with Julia",
    "section": "",
    "text": "Let’s set up some basics and import the necessary packages:\n\nusing CairoMakie\nusing AlgebraOfGraphics\nusing Chain\nusing CSV\nusing Downloads\nusing DataFrames\nusing DataFrameMacros\nusing StatsBase\nusing Dates\n\nCairoMakie.activate!(type = \"svg\")\nset_theme!(theme_minimal())\n\nFirst, we need to download the dataset, which is available on github.\n\nurl = \"https://raw.githubusercontent.com/martj42/international_results/master/results.csv\"\n\ndf = @chain url begin\n    Downloads.download\n    CSV.File(missingstring = \"NA\")\n    DataFrame\nend\n\nfirst(df, 10)\n\n\n10 rows × 9 columns (omitted printing of 2 columns)datehome_teamaway_teamhome_scoreaway_scoretournamentcityDateStringStringInt64Int64StringString3111872-11-30ScotlandEngland00FriendlyGlasgow21873-03-08EnglandScotland42FriendlyLondon31874-03-07ScotlandEngland21FriendlyGlasgow41875-03-06EnglandScotland22FriendlyLondon51876-03-04ScotlandEngland30FriendlyGlasgow61876-03-25ScotlandWales40FriendlyGlasgow71877-03-03EnglandScotland13FriendlyLondon81877-03-05WalesScotland02FriendlyWrexham91878-03-02ScotlandEngland72FriendlyGlasgow101878-03-23ScotlandWales90FriendlyGlasgow\n\n\nLet’s start with a simple question: How did the number of games played per year develop over time? In DataFrameMacros.jl, you can group by columns that you create directly in the groupby call.\nWe can directly visualize the result by chaining the analysis into AlgebraOfGraphics.\n\n@chain df begin\n    @groupby(:year = year(:date))\n    combine(nrow => :n_games)\n    data(_) *\n        mapping(:year => \"Year\", :n_games => \"Number of games\") *\n        visual(Scatter)\n    draw\nend\n\n\n\n\nThere has been a huge growth in the number of games per year. What could have been the driving factors there? We could look at the development of friendly vs. non-friendly games.\nAs soon as there are some groups to plot separately, I like using AlgebraOfGraphics.jl, which does all the work of grouping and legend building for me. I can build one long chain that culminates in a plot, so I don’t have to come up with names for intermediary steps.\n\n@chain df begin\n    @groupby(:year = year(:date), :friendly = :tournament == \"Friendly\")\n    combine(nrow => :n_games)\n    data(_) *\n        mapping(:year => \"Year\", :n_games => \"Number of games\",\n            color = :friendly => nonnumeric) *\n        visual(Scatter)\n    draw\nend\n\n\n\n\nSo we can see that both friendlies and competitions have become much more numerous, although the competitions are responsible for the larger share.\nAnother way we could look at this information is to count the number of different competitions per year:\n\n@chain df begin\n    @subset(:tournament != \"Friendly\")\n    @groupby(:year = year(:date))\n    @combine(:n_competitions = length(unique(:tournament)))\n    data(_) *\n        mapping(:year => \"Year\", :n_competitions => \"Number of competitions\") *\n        (visual(Scatter, markersize = 5) + smooth())\n    draw\nend\n\n\n\n\nAnd of course the average number of teams per competition:\n\n@chain df begin\n    @subset(:tournament != \"Friendly\")\n    @groupby(:year = year(:date), :tournament)\n    @combine(:n_teams = @c length(unique(vcat(:home_team, :away_team))))\n    data(_) *\n        mapping(:year => \"Year\", :n_teams => \"Number of teams per competition\") *\n        (visual(Scatter, markersize = 4, color = (:black, 0.3)) + smooth() * visual(linewidth = 3))\n    draw\nend\n\n\n\n\nSo both the number of competitions, as well as the number of teams taking part in each competition has increased over the years.\nLet’s check out how the number of goals per game during world cups has developed over time. As football has become more and more professionalized, do the highly trained players of today score more or fewer goals? (The defense is also better trained, of course.)\n\n@chain df begin\n    @subset(:tournament == \"FIFA World Cup\")\n    @transform(:year = year(:date))\n    @transform(:n_goals = :home_score + :away_score)\n    @groupby(:year)\n    @combine(:average_goals = mean(:n_goals))\n    data(_) *\n        mapping(:year => \"Year\", :average_goals => \"Average goals per game\") *\n        (visual(Scatter) + smooth())\n    draw(axis = (limits = (nothing, (0, nothing)),))\nend\n\n\n\n\nIt seems the number of goals has gone down over time, from around 4 to 2.5 or so, where it has plateaued. This dataset can give no indication, though, what the reasons for this development might be.\nOne thing we can look at, though, is the distribution of goal differences over time. Maybe the teams were just much more different in ability before?\nWe could make histograms for 1954 and 1990, which had high and low averages, respectively.\n\n@chain df begin\n    @transform(:year = year(:date))\n    @subset(:tournament == \"FIFA World Cup\", :year in (1954, 1990))\n    @transform(:goal_difference = abs(:home_score - :away_score))\n    data(_) *\n        mapping(:goal_difference  => \"Goal difference\",\n            col = :year => nonnumeric) *\n        frequency()\n    draw\nend\n\n\n\n\nSo there were even games with 7 or 9 goals difference in 1954, suggesting that at least some of the matches might have been quite unbalanced at the time, driving a higher goal average.\nIn 1990, most games were decided by one goal difference, in comparison.\nLet’s turn to another question, that of the home team advantage. For a quick glance, we can compute the probability of winning as the home team.\n\n@chain df begin\n    @subset(_, !:neutral; skipmissing = true)\n    @transform(:home_result = @m :home_score > :away_score ?\n        \"win\" : :away_score > :home_score ? \"lose\" : \"tie\")\n    dropmissing(:home_result)\n    @aside n = nrow(_)\n    @groupby(:home_result)\n    @combine(:p = length(:home_result) / n)\nend\n\n\n3 rows × 2 columnshome_resultpStringFloat641tie0.2313352win0.5059473lose0.262718\n\n\nIt looks like the probability to win as the home team is about 50%, so twice as likely as losing. This could be a bit misleading, potentially, if the better teams are also somehow the teams that host more games.\nSo we could check how it looks if we compute the win lose ratio for each team separately. One problem is that each “team” (country) changes all the time, and Germany from 1950 has nothing in common with Germany from 2020. As an approximation, we can split the timeline into 5 year bins, and calculate the ratio within those.\n\n@chain df begin\n    @subset(_, !:neutral; skipmissing = true)\n    @transform(:home_result = @m :home_score > :away_score ?\n        \"win\" : :away_score > :home_score ? \"lose\" : \"tie\")\n    dropmissing(:home_result)\n    @transform(:fiveyears = year(:date) - year(:date) % 5)\n    stack([:home_team, :away_team], variable_name = :type,\n        value_name = :team)\n    @transform(:result = if :type == \"home_team\"\n        :home_result\n    else\n        :home_result == \"win\" ? \"lose\" :\n            :home_result == \"lose\" ? \"win\" : \"tie\"\n    end)\n    @subset(:result != \"tie\")\n    @groupby(:fiveyears, :team, :type, :result)\n    combine(nrow  => :count)\n    unstack(:result, :count)\n    @transform(:win = coalesce(:win, 0), :lose = coalesce(:lose, 0))\n    @transform(:p_win = :win / (:win + :lose))\n    unstack([:fiveyears, :team], :type, :p_win)\n    @transform(:home_p_win_delta = :home_team - :away_team)\n    dropmissing(:home_p_win_delta)\n    data(_) *\n        mapping(:fiveyears => \"Five year period\", :home_p_win_delta => \"p(win) - p(lose)\") *\n        (visual(Scatter, markersize = 5, color = (:black, 0.2)) + smooth())\n    draw\nend\n\n\n\n\nEven though this is only a pretty rough analysis, the home advantage appears to hold up when looking at it within each team, separately over time.\nThis was an example of data analysis and plotting with DataFrameMacros.jl and AlgebraOfGraphics.jl. I hope you learned something new, either about Julia, or about international football."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "",
    "text": "If you’re new to Julia, here is a scenario that might have tripped you up already: Let’s define two points. Both are just a collection of two floating point numbers. But one is a Vector, written with the [] syntax, and one a Tuple, written with the () syntax. Then we make vectors of both types of points and run a short computation. Let’s see what the performance difference looks like.\nThe Vector version is much slower than the Tuple version. But why? Are Vectors bad and Tuples good?\nIn the following post I’ll try to explain in simple terms why we see such a big difference and how you can use your new knowledge to write better code in Julia."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#allocations",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#allocations",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Allocations",
    "text": "Allocations\nThe @time outputs show that there were 250,000 allocations for the vector version and only 2 for the tuple version. What does that mean and why does it make the code slow?\nAn allocation is a request for memory. Our program tells the operating system “I need space to store some values” and the operating system gives back the location of some empty space in our RAM we can use.\nAsking the operating system for memory takes time, therefore more allocations make our code slower. So far, so good.\nIn the vector case, this happened 250,000 times, or once for each entry in the 500 x 500 distance matrix. In the tuple code it happened only twice.\nBut isn’t that weird?\nIn both cases, each point consists of two floating point numbers. Each computation generates the exact same number of points. So why do we need to ask for more memory in the vector version?\nThis leads us to the next important piece of the puzzle: We need to look at what the stack and the heap are."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#stack-and-heap",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#stack-and-heap",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Stack And Heap",
    "text": "Stack And Heap\nMany programming languages work with two concepts called the stack and the heap. These concepts are just two different ways of organizing memory, which influence the speed with which programs run.\nThe heap is comparable to a big space where stored objects are scattered all over the place. Some objects are big, some are small, and there may be large or small gaps between them. The heap is a bit messy, but it is also spacious. If you want to store a new object there, the operating system finds a suitable location for you and gives you the address.\nThe stack on the other hand has a very strict order. It’s like a tower of objects which are stacked neatly in memory, one on top of the other. There are no gaps between them, and you can’t just pull out objects from the middle. You can only take off the topmost object or stack new ones on top of that one. New objects are always stored on top, never anywhere else.\nWhy do we have the two kinds?\nThe heap is for all objects that can dynamically change in size and for objects that should live longer in memory. If you need more or less space for some object which is on the heap, you can maybe expand it into some empty space around it, or you have to find a new place and copy it there. The stack on the other hand can only be built out of objects that never change in size. Imagine how that neat tower would react if an object right in the middle suddenly shrank or expanded?\nThat’s not allowed.\nThis might seem restrictive, but on the other hand it makes the stack really fast. Our program always knows where each object in the stack is and what size it has. We also never need to ask the operating system for additional memory when storing things on the stack. That’s because we have preallocated memory for it that should be enough for almost all purposes (as long as we don’t just keep stacking on top without removing things in between, then you get one of the famed stack overflows).\nTo sum up, using stack memory is much faster than allocating on the heap. The problem is that not every object can be stored on the stack, only those that never change in size can be.\nHow does that relate to our Vectors and Tuples? It’s simple: Vectors are mutable and Tuples are not."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#mutable-and-immutable-objects",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#mutable-and-immutable-objects",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Mutable And Immutable Objects",
    "text": "Mutable And Immutable Objects\nAt first glance, the two descriptions of a point [rand(), rand()] and (rand(), rand()) might look really similar, and obviously we could run the same function with both versions. The difference is that the Vector created with [] is mutable, and the Tuple created with () is immutable.\nFor example this works:\nvector_point = [1.0, 2.0]\npush!(vector_point, 3.0)\n3-element Array{Float64,1}:\n 1.0\n 2.0\n 3.0\nAnd this doesn’t:\ntuple_point = (1.0, 2.0)\npush!(tuple_point, 3.0)\nERROR: MethodError: no method matching push!(::Tuple{Float64,Float64}, ::Float64)\nAnother important difference is the exact type of each object. The vector point is of type Array{Float64,1}, or a one-dimensional array of Float64s. The tuple point is of type Tuple{Float64,Float64}, or a tuple of exactly two Float64s.\nNotice the difference? The tuple type guarantees that there are always exactly two elements in our point. The Array{Float64,1} makes no such guarantee.\nIn Julia, a generic function has a method compiled for each combination of specific types of input arguments that we give it. So the method of difference_matrix(points) where points is a Vector of points of type Array{Float64,1} doesn’t know how many elements such points have, or how much memory will be needed for the resulting points, or even the matrix storing these points. That all has to be determined dynamically. Dynamic is slow!\nWhen the compiler compiles the method of difference_matrix(points) that uses points of type Tuple{Float64, Float64}, it has so much more information. It knows that each point has a specific width in memory. It knows that for each subtraction operation, the exact same size will be needed on the stack. It also knows that the resulting Matrix of points can be stored contiguously in memory.\nContiguous means packed tightly together. We can do that with the tuple points because again we know their size beforehand. With the vector points, we don’t know that. The matrix that stores our vector points actually only stores the addresses for each of the little mutable point vectors. These vectors are then scattered all over the heap, with no guaranteed order that the computer could make use of. This should strike you as a really messy way of dealing with a simple matrix of points, and you would be right. The array of tuples where all points are packed together like sardines is much better.\nNotice that the matrix of tuples itself is not stored on the stack, but is stored in contiguous fashion on the heap. As long as we only need one allocation for that big piece of memory, that cost disappears compared to the computations we do with that memory. The 250,000 allocations in the vector case come from each individual Vector that results from the subtraction of two existing Vectors. For the matrix that stores the addresses of those individual vectors we again need only one allocation, because the memory addresses of mutable objects are themselves immutable objects of fixed size…"
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#its-not-just-tuples",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#its-not-just-tuples",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "It’s Not Just Tuples",
    "text": "It’s Not Just Tuples\nThe mechanism explained above is not specific to tuples. It works with basically every immutable data structure that has a fixed size in memory given its type. For example, we could define a point as an immutable struct containing exactly two Float64s and would enjoy similar benefits:\nstruct Point\n    x::Float64\n    y::Float64\nend\nActually, such a point would have the exact same memory footprint as a Tuple{Float64,Float64} and the compiler might even treat them exactly the same on a machine code level.\nThe important thing is that the type of our point gives the compiler complete information about the size in memory. Often, the compiler depends on knowing the exact type of objects that are stored in a collection. And it’s not immediately better just because that type is a Tuple.\nFor example, you can store points of type Tuple{Float64, Float64} in a vector with parametric type Tuple{Any,Any}. This basically hides the true identity of our points from the compiler and results in abysmal performance:\nanytuple_points  = Tuple{Any,Any}[rand_tuple_point()  for _ in 1:500]\n\nprintln(\"We have hidden our points in an $(typeof(anytuple_points))\")\n\ndifference_matrix(anytuple_points)\n\nprintln(\"AnyTuple version:\")\n@time difference_matrix(anytuple_points)\nWe have hidden our points in an Array{Tuple{Any,Any},1}\nAnyTuple version:\n  0.109928 seconds (1.75 M allocations: 68.680 MiB, 8.43% gc time)\nThe instructions the compiler created for Tuple{Any,Any} points are much more bloated, because who knows what those tuples contain? Could it be Float64s by chance? The issue above actually leads to a very important concept in Julia called type stability which is another huge factor influencing performance, but is too much for this post."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#stack-those-immutables",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#stack-those-immutables",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Stack Those Immutables",
    "text": "Stack Those Immutables\nTo conclude this introduction, always check that your types are as concrete as possible, that your data structures can be represented by pure bit patterns and stored on the stack if possible. The function isbits helps to figure out if your objects have those desired properties. For example, isbits([1, 2]) == false but isbits((1, 2)) == true.\nYou might never really have encountered immutable data structures if you come from languages like R or Matlab, but they are a big reason why Julia code can be so much faster, so make use of them! If you deal with data structures of known size, preferably use tuples or immutable structs (or check out StaticArrays.jl, which has tuples dressed up as arrays for convenience).\nYou’ll make your compiler’s and therefore your computer’s job much easier, and end up with more efficient and fast code in the process.\nThis is also not nearly all there is to say about the difference between Tuples and Vectors, but it should hopefully get some of the biggest misconceptions out of the way!"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html",
    "href": "pages/2022-08-26-pkg-introduction/index.html",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "",
    "text": "When you start using Julia, you will quickly come in contact with Pkg.jl, its package manager. It’s reasonably easy to install a few packages and start using Julia. But from reading questions on Slack and Discourse, many users only start understanding relatively late what commands like instantiate are doing. This post should teach you how you can step beyond a messy global environment and towards neatly packaged local versions that allow you to collaborate more effectively and make your results reproducible."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#getting-started",
    "href": "pages/2022-08-26-pkg-introduction/index.html#getting-started",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Getting started",
    "text": "Getting started\nWhen you install Julia for the first time, there are no environments. Let’s say you installed Julia 1.8. When you start the REPL with the julia command, you will see the standard prompt\njulia> \nFrom there, you get to the Pkg.jl REPL mode by typing ]. The prompt will change to indicate this, by showing the name of the active environment:\n(@v1.8) pkg> \nBut wait, didn’t I just say there are no environments, yet? That’s true, there shouldn’t be any environment files on your computer. You can check the .julia/environments folder, it should be empty. This folder contains all your “shared” environments. You can tell that an environment is shared by the leading @ character in the package REPL prompt, in our case @v1.8 because we use Julia 1.8.\n(Note that if you already have a folder called v1.8, or whatever Julia version you’re using, you can just rename that to v1.8_deactivated or something and restart Julia for the purposes of this tutorial.)\nIf a new environment is activated, this doesn’t yet create any files, and that’s why we don’t have any files in .julia/environments, yet. They only appear once you actually do something with your environment.\nWe can test this quickly. Activate a new environment by typing (@v1.8) pkg> activate MyEnvironment. You won’t see any new files being created in your working directory, as I said this only happens once you manipulate an environment. But the prompt will have changed:\n(@v1.8) pkg> activate MyEnvironment\n  Activating new project at `~/MyEnvironment`\n\n(MyEnvironment) pkg> \nLet’s switch back to the “main” environment @v1.8 for now.\nThe purpose of shared environments is that you can activate them easily from any working directory because they start with @, and Pkg knows to look for them in .julia/environments. For all other environments, you can activate them by name if you are in the directory where they were created, or you have to specify the full path.\nSo we activate @v1.8 again by typing:\n(MyEnvironment) pkg> activate @v1.8\n  Activating project at `~/.julia/environments/v1.8`\n\n(@v1.8) pkg> \nAs you see, Pkg told us we were activating a new project (another word for environment), because as we saw before, no files did actually exist, yet.\nThere’s another shortcut to activate the main environment, which is activate without an argument:\n(@v1.8) pkg> activate\n  Activating project at `~/.julia/environments/v1.8`\n\n(@v1.8) pkg>"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#adding-a-package",
    "href": "pages/2022-08-26-pkg-introduction/index.html#adding-a-package",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Adding a package",
    "text": "Adding a package\nLet’s add our first package to our shared @v1.8 environment. For this, we use the add command. I choose the MacroTools package because it has few dependencies.\n(@v1.8) pkg> add MacroTools\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] + MacroTools v0.5.9\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] + MacroTools v0.5.9\n  [2a0f44e3] + Base64\n  [d6f4376e] + Markdown\n  [9a3f8284] + Random\n  [ea8e919c] + SHA v0.7.0\n  [9e88b42a] + Serialization\n\nAs you probably know, after doing this, the MacroTools code has been downloaded onto your system and you can use it in your own code:\njulia> using MacroTools\nSo what actually happened when we ran the add command?\nIn the first line, you can see that the general registry was updated. The general registry (https://github.com/JuliaRegistries/General) is a list of third-party packages that are available to the public, where each package lists all its dependencies and versions. There can be other registries, even private ones, but the general registry is the main one which will be the only one relevant for most users.\nPkg has first updated this list on our computer when we ran add MacroTools so that it knows about the most recent versions of all packages in the ecosystem. You can have a look at it in .julia/registries/ if you want.\nAfter updating the registry, Pkg is Resolving package versions. First, MacroTools latest version at the time of writing, v0.5.9, was added to ~/.julia/environments/v1.8/Project.toml. So at this point in time, finally the environment file I was talking about earlier is being created.\nWe can look at the content of Project.toml:\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nSo this just says that our environment has one dependency declared, which is MacroTools.jl. The UUID string 1914dd2f-81c6... is there because that’s the “real” unique identifier of the package because, e.g., if another hypothetical registry had a different MacroTools, then at least you could specify the one you really want via the UUID.\nPkg also updated the file ~/.julia/environments/v1.8/Manifest.toml. Let’s have a look at this one:\n# This file is machine-generated - editing it directly is not advised\n\njulia_version = \"1.8.0-rc3\"\nmanifest_format = \"2.0\"\nproject_hash = \"e39ab6d265da4acedccb7411db33219b8d7db4fc\"\n\n[[deps.Base64]]\nuuid = \"2a0f44e3-6c83-55bd-87e4-b1978d98bd5f\"\n\n[[deps.MacroTools]]\ndeps = [\"Markdown\", \"Random\"]\ngit-tree-sha1 = \"3d3e902b31198a27340d0bf00d6ac452866021cf\"\nuuid = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nversion = \"0.5.9\"\n\n[[deps.Markdown]]\ndeps = [\"Base64\"]\nuuid = \"d6f4376e-aef5-505a-96c1-9c027394607a\"\n\n[[deps.Random]]\ndeps = [\"SHA\", \"Serialization\"]\nuuid = \"9a3f8284-a2c9-5f02-9a11-845980a1fd5c\"\n\n[[deps.SHA]]\nuuid = \"ea8e919c-243c-51af-8825-aaa63cd721ce\"\nversion = \"0.7.0\"\n\n[[deps.Serialization]]\nuuid = \"9e88b42a-f829-5b0c-bbe9-9e923198166b\"\nThe Manifest.toml lists all the packages that were actually installed for you, while the Project.toml only lists the MacroTools dependency.\nYou can think of the two files this way:\n\nProject.toml: What you want.\nManifest.toml: What you get.\n\nThe Project.toml is always the first file being edited when you make environment changes, if that is through the Pkg REPL or manually. The Manifest.toml is then the result of a computation that tries to find compatible versions of all packages specified in the Project.toml and their dependencies. Note that Project.toml can in principle specify impossible demands, like two packages that require incompatible dependencies. A Manifest.toml however should always be in a valid state, if no valid configuration of package dependencies can be resolved, you will just get an error.\nWe can see the dependency graph that Pkg resolved in the Manifest.toml, if we look at the deps fields:\n\n\n\n\n\n\n\nG\n\n  \n\nMacroTools\n\n MacroTools v0.5.9   \n\nMarkdown\n\n Markdown   \n\nMacroTools->Markdown\n\n    \n\nRandom\n\n Random   \n\nMacroTools->Random\n\n    \n\nBase64\n\n Base64   \n\nMarkdown->Base64\n\n    \n\nSHA\n\n SHA v0.7.0   \n\nRandom->SHA\n\n    \n\nSerialization\n\n Serialization   \n\nRandom->Serialization\n\n   \n\n\n\n\n\nThe blue nodes have versions and the red ones do not, that’s because the red ones are standard libraries. Standard libraries are shipped with Julia, so they don’t have their own version. They only change with each Julia release. But as you can see, even standard libraries can depend on other, even, external packages, as SHA is not a normal standard library (it’s hosted externally) and has a version.\nYou can check the versions of libraries in your Project.toml and Manifest.toml with the status or st command. With the -m flag you can see the Manifest.toml entries, which can be important for checking which dependencies were resolved.\n(@v1.8) pkg> st\nStatus `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] MacroTools v0.5.9\n\n(@v1.8) pkg> st -m\nStatus `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] MacroTools v0.5.9\n  [2a0f44e3] Base64\n  [d6f4376e] Markdown\n  [9a3f8284] Random\n  [ea8e919c] SHA v0.7.0\n  [9e88b42a] Serialization\n\n(@v1.8) pkg> st -m SHA\nStatus `~/.julia/environments/v1.8/Manifest.toml`\n  [ea8e919c] SHA v0.7.0"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#version-numbers",
    "href": "pages/2022-08-26-pkg-introduction/index.html#version-numbers",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Version numbers",
    "text": "Version numbers\nTo understand how dependencies are resolved, you have to understand SemVer versioning. SemVer stands for semantic versioning, which just means that version numbers should be meaningful, not just random labels. The three parts of the version number are major.minor.patch. In Julia, all newer versions with the same major version should have compatible public APIs, so code that works with v1.2.3 should also work with v1.20.5. The exception is major version 0, where each new minor version can be considered potentially breaking. So code that works with v0.2.4 should still work with v0.2.13 but not necessarily with v0.3.0. This is because package developers want to be able to make breaking changes even if they haven’t brought their package to v1.0 yet, a version that usually carries the implication of public API stability and is often reached only after the package has been around for a while."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#adding-specific-variants-of-a-package",
    "href": "pages/2022-08-26-pkg-introduction/index.html#adding-specific-variants-of-a-package",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Adding specific variants of a package",
    "text": "Adding specific variants of a package\nSo far, we have only used the command add MacroTools, which pulled the latest version v0.5.9 into our environment. Sometimes, however, you want a specific variant of a package. That doesn’t necessarily have to be a specific version. It can also be a commit or branch of a certain repository. Let’s try this out with MacroTools.\nWe can install the version v0.5.1 by using the @ syntax:\n(@v1.8) pkg> add MacroTools@0.5.1\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n⌃ [1914dd2f] ↓ MacroTools v0.5.9 ⇒ v0.5.1\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n⌅ [00ebfdb7] + CSTParser v2.5.0\n⌅ [34da2185] + Compat v2.2.1\n⌅ [864edb3b] + DataStructures v0.17.20\n⌃ [1914dd2f] ↓ MacroTools v0.5.9 ⇒ v0.5.1\n  [bac558e1] + OrderedCollections v1.4.1\n  [0796e94c] + Tokenize v0.5.24\n  [0dad84c5] + ArgTools v1.1.1\n  [56f22d72] + Artifacts\n  [ade2ca70] + Dates\n  [8bb1440f] + DelimitedFiles\n  [8ba89e20] + Distributed\n  [f43a241f] + Downloads v1.6.0\n  [7b1f6079] + FileWatching\n  [b77e0a4c] + InteractiveUtils\n  [b27032c2] + LibCURL v0.6.3\n  [76f85450] + LibGit2\n  [8f399da3] + Libdl\n  [37e2e46d] + LinearAlgebra\n  [56ddb016] + Logging\n  [a63ad114] + Mmap\n  [ca575930] + NetworkOptions v1.2.0\n  [44cfe95a] + Pkg v1.8.0\n  [de0858da] + Printf\n  [3fa0cd96] + REPL\n  [1a1011a3] + SharedArrays\n  [6462fe0b] + Sockets\n  [2f01184e] + SparseArrays\n  [10745b16] + Statistics\n  [fa267f1f] + TOML v1.0.0\n  [a4e569a6] + Tar v1.10.0\n  [8dfed614] + Test\n  [cf7118a7] + UUIDs\n  [4ec0a83e] + Unicode\n  [e66e0078] + CompilerSupportLibraries_jll v0.5.2+0\n  [deac9b47] + LibCURL_jll v7.83.1+1\n  [29816b5a] + LibSSH2_jll v1.10.2+0\n  [c8ffd9c3] + MbedTLS_jll v2.28.0+0\n  [14a3606d] + MozillaCACerts_jll v2022.2.1\n  [4536629a] + OpenBLAS_jll v0.3.20+0\n  [83775a58] + Zlib_jll v1.2.12+3\n  [8e850b90] + libblastrampoline_jll v5.1.1+0\n  [8e850ede] + nghttp2_jll v1.47.0+0\n  [3f19e933] + p7zip_jll v17.4.0+0\n        Info Packages marked with ⌃ and ⌅ have new versions available, but those with ⌅ cannot be upgraded. To see why use `status --outdated -m`\n\nYou can see that we got a ton of new dependencies. This happened because MacroTools managed to cut the number of packages it depends on a lot over time, so the older version pulls in much more.\nIf we take a look at the new Manifest.toml entry for MacroTools, we see:\n[[deps.MacroTools]]\ndeps = [\"CSTParser\", \"Compat\", \"DataStructures\", \"Test\", \"Tokenize\"]\ngit-tree-sha1 = \"d6e9dedb8c92c3465575442da456aec15a89ff76\"\nuuid = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nversion = \"0.5.1\"\nThis just goes to show that even between patch versions of a package, which should all follow the same public API, the dependencies can change a lot.\nIf you look at the Project.toml, you will see that it hasn’t changed. The version requirement was just enforced during this one dependency resolution, and won’t be remembered or enforced again in future Pkg operations.\nLet’s try one other syntax, which is the one for choosing a specific commit or branch from a repository. In this case, we use the commit 639d1a6, but we could also use something like master to fetch the latest commit on that branch.\n(@v1.8) pkg> add MacroTools#639d1a6\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] ~ MacroTools v0.5.1 ⇒ v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [00ebfdb7] - CSTParser v2.5.0\n  [34da2185] - Compat v2.2.1\n  [864edb3b] - DataStructures v0.17.20\n  [1914dd2f] ~ MacroTools v0.5.1 ⇒ v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n  [bac558e1] - OrderedCollections v1.4.1\n  [0796e94c] - Tokenize v0.5.24\n  [0dad84c5] - ArgTools v1.1.1\n  [56f22d72] - Artifacts\n  [ade2ca70] - Dates\n  [8bb1440f] - DelimitedFiles\n  [8ba89e20] - Distributed\n  [f43a241f] - Downloads v1.6.0\n  [7b1f6079] - FileWatching\n  [b77e0a4c] - InteractiveUtils\n  [b27032c2] - LibCURL v0.6.3\n  [76f85450] - LibGit2\n  [8f399da3] - Libdl\n  [37e2e46d] - LinearAlgebra\n  [56ddb016] - Logging\n  [a63ad114] - Mmap\n  [ca575930] - NetworkOptions v1.2.0\n  [44cfe95a] - Pkg v1.8.0\n  [de0858da] - Printf\n  [3fa0cd96] - REPL\n  [1a1011a3] - SharedArrays\n  [6462fe0b] - Sockets\n  [2f01184e] - SparseArrays\n  [10745b16] - Statistics\n  [fa267f1f] - TOML v1.0.0\n  [a4e569a6] - Tar v1.10.0\n  [8dfed614] - Test\n  [cf7118a7] - UUIDs\n  [4ec0a83e] - Unicode\n  [e66e0078] - CompilerSupportLibraries_jll v0.5.2+0\n  [deac9b47] - LibCURL_jll v7.83.1+1\n  [29816b5a] - LibSSH2_jll v1.10.2+0\n  [c8ffd9c3] - MbedTLS_jll v2.28.0+0\n  [14a3606d] - MozillaCACerts_jll v2022.2.1\n  [4536629a] - OpenBLAS_jll v0.3.20+0\n  [83775a58] - Zlib_jll v1.2.12+3\n  [8e850b90] - libblastrampoline_jll v5.1.1+0\n  [8e850ede] - nghttp2_jll v1.47.0+0\n  [3f19e933] - p7zip_jll v17.4.0+0\nNote that even though the version printed for MacroTools is again 0.5.9, this doesn’t necessarily mean that we are on the same commit as the one pointed to by the version 0.5.9 in the registry. It just means that Pkg cloned the repository, checked out the commit with hash 639d1a6 and found the version specifier 0.5.9 in MacroTools’s own Project.toml file. Therefore, infinitely many code versions of a package can be treated as version X.Y.Z by Pkg, but X.Y.Z itself refers only to exactly one version. This distinction is important to remember when developing and editing a package, but more about that later.\nIf we take another look at our Manifest.toml, we can see the following entry for MacroTools:\n[[deps.MacroTools]]\ndeps = [\"Markdown\", \"Random\"]\ngit-tree-sha1 = \"465a4803356bcb11f6eb97df992680f13a9ba776\"\nrepo-rev = \"639d1a6\"\nrepo-url = \"https://github.com/FluxML/MacroTools.jl.git\"\nuuid = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nversion = \"0.5.9\"\nThis time, the URL of the repository was recorded, as well as the revision, which was 639d1a6. This is because as soon as you specify a revision in the add command, Pkg knows you’re operating outside of the registry, so it cannot rely on the repository information stored there for MacroTools.\n(Note that you can also install unregistered packages, or forks of registered packages this way, by doing add https://the_url_to_the_git_repository.)\nThe manifest needs to store the url and revision in order to make the project reproducible by someone else. Let’s actually look at what reproducing an environment looks like:"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#reproducing-an-environment",
    "href": "pages/2022-08-26-pkg-introduction/index.html#reproducing-an-environment",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Reproducing an environment",
    "text": "Reproducing an environment\nLet’s say you have written some code relying on the specific MacroTools version we added via add MacroTools#639d1a6 and want your colleague to be able to run that code with the exact packages installed that we used at the time.\nWhich files do they need to reproduce the state of your environment? Not just the Project.toml, because remember, it still only contains this information:\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nWe need to also send the Manifest.toml because it records the exact versions of all packages. Let’s pretend we are our colleague, and we just received a Project.toml and Manifest.toml file. How do we actually get the environment installed?\nLet’s copy the files into a new folder we call ColleagueEnv in our current working directory.\nTo pretend we’re the colleague who just uses Julia for the first time, we also delete the .julia/packages/MacroTools folder in which the downloaded source code of MacroTools was stored.\nNote that this means that the source code is not part of an environment but stored centrally. It would be pretty wasteful to download the same sources over and over just because you’re using different local environments.\nLet’s now restart Julia and activate the ColleagueEnv environment:\n(@v1.8) pkg> activate ./ColleagueEnv\n  Activating project at `~/ColleagueEnv`\n\nWe can check the installed packages via st -m:\n(ColleagueEnv) pkg> st -m\nStatus `~/ColleagueEnv/Manifest.toml`\n→ [1914dd2f] MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#master`\n  [2a0f44e3] Base64\n  [d6f4376e] Markdown\n  [9a3f8284] Random\n  [ea8e919c] SHA v0.7.0\n  [9e88b42a] Serialization\nInfo Packages marked with → are not downloaded, use `instantiate` to download\n\nIf we were trying to just run some code using MacroTools now, this would happen:\njulia> using MacroTools\nERROR: ArgumentError: Package MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n\nStacktrace:\n [1] _require(pkg::Base.PkgId)\n   @ Base ./loading.jl:1306\n [2] _require_prelocked(uuidkey::Base.PkgId)\n   @ Base ./loading.jl:1200\n [3] macro expansion\n   @ ./loading.jl:1180 [inlined]\n [4] macro expansion\n   @ ./lock.jl:223 [inlined]\n [5] require(into::Module, mod::Symbol)\n   @ Base ./loading.jl:1144\nSo we need to follow the advice already printed twice for us, and call instantiate. This will download everything specified in the Manifest.toml exactly as it was recorded there. You can actually be sure that it’s exactly the same because the Manifest.toml stores git tree hashes of each dependency. Unless someone deletes these specific parts of the repository you will be able to download the source exactly as it was:\n(ColleagueEnv) pkg> instantiate\nPrecompiling project...\n  ✓ MacroTools\n  1 dependency successfully precompiled in 1 seconds\n\n(ColleagueEnv) pkg> st -m\nStatus `~/ColleagueEnv/Manifest.toml`\n  [1914dd2f] MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#master`\n  [2a0f44e3] Base64\n  [d6f4376e] Markdown\n  [9a3f8284] Random\n  [ea8e919c] SHA v0.7.0\n  [9e88b42a] Serialization\n\nNow we don’t get a warning anymore, our dependencies have been downloaded correctly. You will find MacroTools downloaded into the .julia/packages folder again."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#packages-and-environments",
    "href": "pages/2022-08-26-pkg-introduction/index.html#packages-and-environments",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Packages and environments",
    "text": "Packages and environments\nPackages and normal environments are pretty similar. Each package must have a Project.toml which specifies its name, UUID, version and dependencies. The easiest way to make a package to test this out, is to use the generate command of the Pkg REPL.\nLet’s restart Julia and remove MacroTools from our main environment so it is empty:\n(@v1.8) pkg> rm MacroTools\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] - MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] - MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n  [2a0f44e3] - Base64\n  [d6f4376e] - Markdown\n  [9a3f8284] - Random\n  [ea8e919c] - SHA v0.7.0\n  [9e88b42a] - Serialization\nNow, we generate a new package called MyPackage:\n(@v1.8) pkg> generate MyPackage\n  Generating  project MyPackage:\n    MyPackage/Project.toml\n    MyPackage/src/MyPackage.jl\n\nAs you can see, a Project.toml file was generated in the MyPackage directory.\nLet’s have a look at this one:\nname = \"MyPackage\"\nuuid = \"025f59cc-7e1c-467d-8f56-70157e1cbbbb\"\nauthors = [\"Your Name <your@email.com>\"]\nversion = \"0.1.0\"\nThe only difference from a basic package environment to a normal environment are those four fields. If we want to use MacroTools in our package, we can add it manually to a deps section in the Project.toml, or we use the Pkg REPL. For that, we first activate the package as an environment, then we add MacroTools.\n(@v1.8) pkg> activate MyPackage/\n  Activating project at `~/MyPackage`\n\n(MyPackage) pkg> add MacroTools\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n   Installed MacroTools ─ v0.5.9\n    Updating `~/MyPackage/Project.toml`\n  [1914dd2f] + MacroTools v0.5.9\n    Updating `~/MyPackage/Manifest.toml`\n  [1914dd2f] + MacroTools v0.5.9\n  [2a0f44e3] + Base64\n  [d6f4376e] + Markdown\n  [9a3f8284] + Random\n  [ea8e919c] + SHA v0.7.0\n  [9e88b42a] + Serialization\nPrecompiling project...\n  ✓ MacroTools\n  ✓ MyPackage\n  2 dependencies successfully precompiled in 1 seconds\n\nThe Project.toml now looks like this:\nname = \"MyPackage\"\nuuid = \"025f59cc-7e1c-467d-8f56-70157e1cbbbb\"\nauthors = [\"Your Name <your@email.com>\"]\nversion = \"0.1.0\"\n\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nIn the file MyPackage/src/MyPackage.jl, we can now import MacroTools and work with it. Let’s change the content of that file to:\nmodule MyPackage\n\nimport MacroTools\n\nfunction test()\n    MacroTools.@capture :(1 + 2) x_ + y_\n    @show x\n    @show y\n    return\nend\n\nend # module MyPackage\nWe can now import or using our package and verify that MacroTools can be used by its source code:\njulia> using MyPackage\n\njulia> MyPackage.test()\nx = 1\ny = 2\n\nThat worked!\nLet’s restart Julia now, which will bring us back to the main environment. Let’s try again to import our package:\njulia> using MyPackage\nERROR: ArgumentError: Package MyPackage not found in current path.\n- Run `import Pkg; Pkg.add(\"MyPackage\")` to install the MyPackage package.\nStacktrace:\n [1] macro expansion\n   @ ./loading.jl:1163 [inlined]\n [2] macro expansion\n   @ ./lock.jl:223 [inlined]\n [3] require(into::Module, mod::Symbol)\n   @ Base ./loading.jl:1144\n\nThis doesn’t work, because our main environment doesn’t have MyPackage installed. You can use MyPackage as long as you have its own environment activated, but outside of that it is not visible.\nWe can change that by using the develop or dev command of the Pkg REPL, which will install and track MyPackage:\n(@v1.8) pkg> dev ./MyPackage/\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [025f59cc] + MyPackage v0.1.0 `../../../MyPackage`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] + MacroTools v0.5.9\n  [025f59cc] + MyPackage v0.1.0 `../../../MyPackage`\n  [2a0f44e3] + Base64\n  [d6f4376e] + Markdown\n  [9a3f8284] + Random\n  [ea8e919c] + SHA v0.7.0\n  [9e88b42a] + Serialization\n\nGreat, that worked. Now we can access MyPackage again:\njulia> using MyPackage\n[ Info: Precompiling MyPackage [025f59cc-7e1c-467d-8f56-70157e1cbbbb]\n\njulia> MyPackage.test()\nx = 1\ny = 2\n\nWhy would we want to do this, use a separate environment to access our package environment? It’s because we might want to use packages that should not be dependencies of MyPackage while developing it."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#compatibility-bounds",
    "href": "pages/2022-08-26-pkg-introduction/index.html#compatibility-bounds",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Compatibility bounds",
    "text": "Compatibility bounds\nCurrently our package MyPackage does not specify the versions of MacroTools with which it is compatible. That is usually not a good idea, in fact, the general registry doesn’t allow packages to be registered if they don’t specify upper compatibility boundaries for each dependency. That makes sense because you don’t know if your package will be compatible with all future versions of your dependencies, so it makes sense to cap the compatibility to the point where you have tested everything works.\nLet’s pretend we tested our package only up to MacroTools version 0.5.8. We can write this requirement into the Project.toml of MyPackage:\nname = \"MyPackage\"\nuuid = \"025f59cc-7e1c-467d-8f56-70157e1cbbbb\"\nauthors = [\"Your Name <your@email.com>\"]\nversion = \"0.1.0\"\n\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\n\n[compat]\nMacroTools = \"<0.5.9\"\nBut this change is not picked up automatically by the @v1.8 environment. To recompute the dependency graph and throw away the old Manifest.toml, we can run update or up:\n(@v1.8) pkg> up\n    Updating registry at `~/.julia/registries/General.toml`\n   Installed MacroTools ─ v0.5.8\n  No Changes to `~/.julia/environments/v1.8/Project.toml`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n⌃ [1914dd2f] ↓ MacroTools v0.5.9 ⇒ v0.5.8\n        Info Packages marked with ⌃ have new versions available\nPrecompiling project...\n  ✓ MacroTools\n  ✓ MyPackage\n  2 dependencies successfully precompiled in 2 seconds\n  \nAs you can see, the MacroTools package was correctly downgraded to v0.5.8.\nWhat would happen if we now tried to install v0.5.9 into the main environment?\n(@v1.8) pkg> add MacroTools@0.5.9\n   Resolving package versions...\nERROR: Unsatisfiable requirements detected for package MacroTools [1914dd2f]:\n MacroTools [1914dd2f] log:\n ├─possible versions are: 0.4.3-0.5.9 or uninstalled\n ├─restricted to versions 0.0.0-0.5.8 by MyPackage [025f59cc], leaving only versions 0.4.3-0.5.8\n │ └─MyPackage [025f59cc] log:\n │   ├─possible versions are: 0.1.0 or uninstalled\n │   └─MyPackage [025f59cc] is fixed to version 0.1.0\n └─restricted to versions 0.5.9 by an explicit requirement — no versions left\n\nWe get a version compatibility conflict. It is not possible to reconcile the requirement of adding MacroTools 0.5.9 with the fact that it is only allowed to reach up to 0.5.8 for MyPackage.\nCompatibility conflicts are the main reason why you should give each of your projects its own local environment instead of always using the global one. First of all, you’re more and more likely to end up with old versions or compatibility clashes, the more packages you install. Second, if you inadvertently update your main environment for project B, but later go back to project A, it could very well be that the new package versions are now incompatible with the code you wrote for A at the time. You don’t want to tangle all your projects up together, so just make separate environments for each."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#stacked-environments",
    "href": "pages/2022-08-26-pkg-introduction/index.html#stacked-environments",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Stacked environments",
    "text": "Stacked environments\nThere’s another behavior of environments that is potentially very confusing for beginners, and it’s called “stacked environments”. Let’s restart Julia again, and add the package Infiltrator to the main environment:\n(@v1.8) pkg> add Infiltrator\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [5903a43b] + Infiltrator v1.6.1\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [5903a43b] + Infiltrator v1.6.1\n  [b77e0a4c] + InteractiveUtils\n  [3fa0cd96] + REPL\n  [6462fe0b] + Sockets\n  [cf7118a7] + UUIDs\n  [4ec0a83e] + Unicode\nNow we activate the environment of MyPackage:\n<span class=\"sgr-bold sgr-fg-5\">(@v1.8) pkg> </span><span>activate MyPackage\n</span><span class=\"sgr-bold sgr-fg-3\">  Activating</span><span> project at `~/MyPackage`\n</span>\nLet’s see what happens if we load Infiltrator:\njulia> using Infiltrator\nIt worked. But why? Infiltrator is not available in MyPackage’s Project.toml.\nThe reason is that Julia can import packages from multiple environments at the same time. This depends on the LOAD_PATH global variable. Let’s have a look:\njulia> LOAD_PATH\n3-element Vector{String}:\n \"@\"\n \"@v#.#\"\n \"@stdlib\"\n\nThe first entry, \"@\", means “active environment”, so the first place where Julia looked for Infiltrator was in MyPackage’s environment, where it didn’t find it.\nThe second entry, \"@v#.#\" means “the shared environment of this Julia version”, in our case this is @v1.8. That’s why I kept calling this the “main” environment, not only because it’s the default one, but also because it’s always available by default due to the LOAD_PATH configuration. This is where Julia found Infiltrator and loaded it.\nThe third entry, \"@stdlib\", refers to the list of standard libraries that belongs to the current Julia version. This is the reason why we can do using Statistics or using REPL in a new Julia session, even if our main environment is empty.\nThe potential confusion comes from the fact that a user can activate a package environment and work there under the assumption that only package dependencies are available. This might hide the fact that some of the included packages are drawn in from the main environment, which will lead to an error later, if the package is installed to a new environment and can’t access the dependency anymore.\nThe best practice for stacked environments is to use the main environment sparingly. Infiltrator is a good example for a package to install there, because it’s a debugging package and basically never needed as a dependency for another package. On the other hand it’s very useful to have available without further work when developing. Another example is Revise.\nIf you really want to make sure that only the packages from your currently activated project are accessible, you can remove other entries from the load path.\nTo demonstrate this, if we empty the load path we can’t load any package at all, neither Infiltrator from @v1.8, nor MyPackage from our active environment, nor the standard library Statistics:\njulia> empty!(LOAD_PATH)\nString[]\n\njulia> using Infiltrator\n │ Package Infiltrator not found, but a package named Infiltrator is available\n │ from a registry. \n │ Install package?\n │   (MyPackage) pkg> add Infiltrator \n └ (y/n/o) [y]: ERROR: ArgumentError: Package Infiltrator not found in current path, maybe you meant `import/using .Infiltrator`.\n- Otherwise, run `import Pkg; Pkg.add(\"Infiltrator\")` to install the Infiltrator package.\n\njulia> using MyPackage\nERROR: ArgumentError: Package MyPackage not found in current path.\n- Run `import Pkg; Pkg.add(\"MyPackage\")` to install the MyPackage package.\n\njulia> using Statistics\nERROR: ArgumentError: Package Statistics not found in current path.\n- Run `import Pkg; Pkg.add(\"Statistics\")` to install the Statistics package."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#temporary-environments",
    "href": "pages/2022-08-26-pkg-introduction/index.html#temporary-environments",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Temporary environments",
    "text": "Temporary environments\nOne thing that’s useful for quick tests are temporary environments. If you read about a new package and quickly want to try it, but don’t want to mess with your main environment or clutter your working directory with environment files, you can use activate --temp:\n(v1.8) pkg> activate --temp\n  Activating new project at `/var/folders/z5/r5q6djwn5g10k3w279bn37700000gn/T/jl_e4klnB`\n\n(jl_e4klnB) pkg> \nThis environment will only exist until the Julia process exits, so it’s perfect to run something once and then forget about it."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#conclusion",
    "href": "pages/2022-08-26-pkg-introduction/index.html#conclusion",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Conclusion",
    "text": "Conclusion\nThis was a short tour of Pkg and its main functions. I hope it has become more clear how environments work and why you shouldn’t rely on a single global one. It’s quite easy to make one environment per project and the text files created use effectively no space, so there’s no downside to doing this.\nFor more info, have a look at some of these sources:\n\nPkg.jl documentation.\nDrWatson.jl, a tool that tries to make the process of setting up reproducible projects easier.\nTestEnv.jl which helps with the problem of stacked environments in the context of tests (not covered here).\nPkgTemplates.jl which makes creating packages easier."
  },
  {
    "objectID": "pages/2021-05-20-reading-data-from-web/index.html",
    "href": "pages/2021-05-20-reading-data-from-web/index.html",
    "title": "Reading data from the web with CSV.jl, DataFrames.jl and Chain.jl",
    "section": "",
    "text": "Here’s the dataset if you want to look at it. The challenge is simply that it’s a non-standard file format that needs to be massaged into a form ready for CSV reading first. That means there are also no predefined column names and we don’t want to do a lot of work to write all of these out manually, but use the repetitive structure. My goal is always to write as little unnecessary boilerplate code as possible, without using too much unreadable magic.\nHere’s the final code, afterwards I’ll go through the different statements one by one.\nThe versions used were CSV v0.8.4, Chain v0.4.5 and DataFrames v1.1.1 with Julia 1.6.\nusing Chain, DataFrames, CSV, Downloads\n\n@chain \"http://homepages.wmich.edu/~hillenbr/voweldata/bigdata.dat\" begin\n    Downloads.download(IOBuffer())\n    String(take!(_))\n    _[findfirst(\"b01ae\", _)[1]:end]\n    replace(r\" +\" => \" \")\n    replace(r\"\\s+$\"m => \"\\n\")\n    CSV.read(IOBuffer(_), DataFrame, header = false,\n        missingstring = \"0\")\n    rename(1:30 .=> [\n        :filename;\n        :duration_msec;\n        Symbol.([\"f0\", \"f1\", \"f2\", \"f3\"], \"_steady\");\n        [Symbol(f, \"_\", p)\n            for p in 10:10:80\n            for f in [\"f1\", \"f2\", \"f3\"]]\n    ])\n    transform(:filename =>\n        ByRow(f -> (\n            type = f[1],\n            number = parse(Int, f[2:3]),\n            vowel = f[4:5]\n        )) => AsTable)\n    transform(:type =>\n        ByRow(t -> Dict(\n            'm' => \"man\",\n            'w' => \"woman\",\n            'b' => \"boy\",\n            'g' => \"girl\")[t]) => :type)\n    select(1:2, 31:33, 3:30)\n    CSV.write(\"hillenbrand.csv\", _)\nend\nOk, let’s look at the parts:\n@chain \"http://homepages.wmich.edu/~hillenbr/voweldata/bigdata.dat\" begin\nFirst, we start a @chain from Chain.jl with the url we want to download. In a chain, we can feed the result from one expression into the first argument of the next, unless we specify a different position with the _ placeholder.\nDownloads.download(IOBuffer())\nString(take!(_))\nWe download the content at the url right into an IOBuffer object, which avoids creating a separate file. The IOBuffer is then converted into a string because we have to clean it up a bit.\n_[findfirst(\"b01ae\", _)[1]:end]\nreplace(r\" +\" => \" \")\nreplace(r\"\\s+$\"m => \"\\n\")\nThe first line finds the occurence of the first part of the actual data entries, then selects only the part of the string from there on out. The second line finds all multiple spaces and replaces them with one space, while the third line removes all trailing whitespace before the end of a line. Both of these things can otherwise throw off CSV.jl when it determines how many columns there are.\nCSV.read(IOBuffer(_), DataFrame, header = false,\n    missingstring = \"0\")\nNow we convert the string back to an IOBuffer, so that we can use it directly with CSV.read. Using the string itself doesn’t work, because CSV.jl would assume it’s a file path. We read into a DataFrame and specify that there’s no header, because the file has no column names. We also specify that the string “0” is a missing value, which is the convention of this dataset but which could easily throw off our analyses if we aren’t careful. Using missing values forces us to acknowledge them explicitly in our analysis.\nrename(1:30 .=> [\n    :filename;\n    :duration_msec;\n    Symbol.([\"f0\", \"f1\", \"f2\", \"f3\"], \"_steady\");\n    [Symbol(f, \"_\", p)\n        for p in 10:10:80\n        for f in [\"f1\", \"f2\", \"f3\"]]\n])\nHere we rename the columns in a succinct way, the structure is described in the data file. We broadcast an integer range from 1 to 30, which is the number of columns, with a list of 30 Symbols. The first two we specify manually, then there’s f0_steady, f1_steady, etc. Finally, we need to make 24 column names which go like f1_10, f2_10, f3_10, f1_20, and so on. We can easily do this with a nested list comprehension, where we loop over the percentages in the outer loop, and over the formants in the inner loop.\ntransform(:filename =>\n    ByRow(f -> (\n        type = f[1],\n        number = parse(Int, f[2:3]),\n        vowel = f[4:5]\n    )) => AsTable)\nThe data file specifies that some information is encoded in the filename. We extract this with a function that operates by row, and extracts the three components into fields of a named tuple. By passing AsTable as the sink, these named tuples are automatically expanded into correctly named columns.\ntransform(:type =>\n    ByRow(t -> Dict(\n        'm' => \"man\",\n        'w' => \"woman\",\n        'b' => \"boy\",\n        'g' => \"girl\")[t]) => :type)\nThe type of speaker is currently encoded as a Char, but we can transform this column to a more readable form by looking up the long version of each character in a small dictionary.\nselect(1:2, 31:33, 3:30)\nOur three new columns have been appended at the end, but it would be nicer if the speaker descriptions were more at the front. So we just use a select statement, where the first two columns come first, then the last three, and then the rest.\nCSV.write(\"hillenbrand.csv\", _)\nAs the last step, we write out the cleaned table into a csv file, and we’ve already reached the end of this short tutorial. This is what the end result looks like:\n1668×33 DataFrame\n  Row │ filename  duration_msec  type    number  vowel   f0_steady  f1_steady  f2_steady  f3_steady  f1_10  f2_10   f3_10    f1_20  f2_20   f3_20    f1_30  f2_3 ⋯\n      │ String    Int64          String  Int64   String  Int64      Int64      Int64?     Int64?     Int64  Int64?  Int64?   Int64  Int64?  Int64?   Int64  Int6 ⋯\n──────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n    1 │ b01ae               257  boy          1  ae            238        630       2423       3166    625    2388     3174    651    2413     3115    675    24 ⋯\n    2 │ b02ae               359  boy          2  ae            286        829       2495       3218    802    2392     3625    778    2461     3424    793    24\n    3 │ b03ae               335  boy          3  ae            214        631       2801       3508    631    2801     3508    602    2760     3453    573    28\n    4 │ b04ae               398  boy          4  ae            239        712       2608       3247    729    2604     3239    712    2608     3247    695    25\n    5 │ b05ae               267  boy          5  ae            200        748       2589       3042    728    2601     3047    752    2562     3033    767    25 ⋯\n    6 │ b07ae               323  boy          7  ae            262        769       2203       3126    769    2203     3126    760    2169     3144    813    22\n    7 │ b08ae               316  boy          8  ae            216        870       2281       3077    765    2252     3214    820    2239     3181    864    23\n    8 │ b09ae               245  boy          9  ae            220        709       2565       3526    626    2545     3504    709    2565     3526    663    26\n    9 │ b10ae               396  boy         10  ae            205        634       2555       3121    635    2560     3230    642    2559     3126    633    25 ⋯\n   10 │ b11ae               298  boy         11  ae            209        630       2509       3112    630    2509     3112    627    2513     3098    616    25\n   11 │ b12ae               415  boy         12  ae            252        736       2505       3332    729    2544     3261    736    2504     3307    739    25\n   12 │ b13ae               281  boy         13  ae            216        634       2535       3260    634    2535     3260    630    2532     3248    623    25\n   13 │ b14ae               314  boy         14  ae            198        697       2418       3371    681    2444     3430    657    2471     3376    697    24 ⋯\n   14 │ b15ae               382  boy         15  ae            272        607       2620       3350    607    2620     3350    617    2599     3369    628    25\n   15 │ b16ae               367  boy         16  ae            187        753       2227       3064    788    2244     3150    750    2233     3042    749    22\n   16 │ b17ae               352  boy         17  ae            246        726       2231       2932    726    2231     2932    742    2246     2902    745    22\n   17 │ b18ae               307  boy         18  ae            249        741       2444       3043    735    2446     3008    746    2455     3021    748    24 ⋯\n   18 │ b19ae               312  boy         19  ae            209        674       2663       3243    684    2665     3268    693    2672     3256    733    26\n   19 │ b21ae               352  boy         21  ae            205        769       2234       2910    766    2245     2917    771    2215     2889    771    21\n   20 │ b22ae               256  boy         22  ae            229        678       2524       3418    687    2580     3288    678    2501     3424    677    25\nAs always, there are lots of ways of achieving the same thing. This is just one version that I was satisfied with, and I hope you have learned one or two new techniques that can be useful to you in the future."
  },
  {
    "objectID": "pages/2020-10-23-julia-bridge/index.html",
    "href": "pages/2020-10-23-julia-bridge/index.html",
    "title": "Julia Helps To Bridge The Gap Between User and Creator",
    "section": "",
    "text": "First off, I am not a trained computer scientist. Almost nobody in my research fields, psychology and neuroscience, is a trained computer scientist. But everybody needs to code nowadays to do research. Experiments are setup with code, data is analysed with code, graphs are made with code. So how does that work out if nobody is really trained for coding?\nIt leads to a situation where people waste time and often produce inferior results because they don’t really grasp the tools they are using. Code is often of low quality, neither version controlled, maintainable nor reproducible. Matlab, R and Python ecosystems offer tools that allow researchers to focus on their direct interest, the data, and spend less time fighting with the compilers and complicated syntax of C++ and Fortran. But this “convenience layer” contributes to a situation where people use tools without a deeper understanding what they are doing, without an idea of what to do when those tools are not enough. We have powerful packages with relatively user-friendly API’s at our disposal in each dynamic language of choice. But the important and performant parts are written in C, C++ and Fortran, hidden from view.\nIt is not easy to find out how things work under the hood in Python, R or Matlab. I think that this creates a big gap between users and creators of scientific tools.\nStudents in a university R or Python data analysis course will probably learn a bit about loops and conditionals first, because that’s just how everyone learning to code starts. But after that first phase, they will quickly move on to learning APIs of packages like dplyr, ggplot, pandas, because that’s what’s actually used by everybody. These API’s tend to be quite removed from the basic building blocks of each language (like the common but non-standard %>% syntax in R). If those tools don’t offer something out of the ordinary as a pre-packaged functionality, the students are out of luck. They know that they shouldn’t attempt to write any serious low-level analysis methods in R or Python directly, because that will probably be slow, and their tools of choice are also not made like that. One of the first things Python, R and Matlab novices learn is “Vectorize everything! Don’t write for-loops, they are slow!”. How surprised would they be to find out that the inside of pandas, dplyr and co is full of for-loops, because they are indispensable building blocks in compiled languages?\nOne such example of the boundaries of existing packages I’ve encountered in my previous work was when I analysed head movement data with Python’s pandas library. I really wanted a column in my dataframe that had one rotation matrix per row, describing head orientation over time. But that was not possible to do effectively because a rotation matrix is just not a data type that pandas expects you to store in a column. At every corner my “weird” datatype caused problems with underlying assumptions of pandas, or numpy or matplotlib. In Julia, it would have been really easy to make a Vector with 3x3 matrices from StaticArrays.jl. DataFrames.jl doesn’t care what your column vectors contain. To me, the point was not even to have the fastest solution, just to have a solution that cleanly expressed my intent.\nThe two-language problem is often presented as an inconvenience to researchers because of its time cost. I think it is a bit more than that. True, it takes a lot of time to figure out a solution to a problem in a dynamic language and then transfer it faithfully to a compiled language, to write bug-free bindings and package everything up for reuse. Julia tries to solve that problem, and it does very well to bridge the gap between a glue language with simple syntax and a serious numerical powerhouse. Countless benchmarks can attest to its speed. But when we focus only at how much time it takes to use two languages, I think we overlook what kind of effect a language gap has on research communities in this age of code.\nThe Julia community is filled with people from diverse scientific backgrounds. Many of them, like me, are not computer scientists. That doesn’t stop them from being involved in writing serious low level packages. And if they are not writing packages themselves, they are often helping by filing issues and creating PRs, adding their own perspectives on design questions. They do this even for the Julia language itself, if they find bugs or API inconsistencies. When I was using Matlab, Python and R, I didn’t see other researchers contribute to the fundamentals of their respective ecosystems in this way. In Julia, I see it all the time.\nThis is possible, in my opinion, because there is a continuous path from surface-level glue code to close-to-the-metal high-performance code in Julia, which can be discovered almost playfully - usually driven by the desire to reduce the number of allocations or runtime of a small function. In Julia, novices can learn first principles in a beginner friendly way, without caring about types, writing code that looks basically like Python. These first principles don’t lose their importance when serious packages are discovered. They instead become ever more powerful, the more knowledge a new user absorbs, because they can be combined in more and more flexible and innovative ways. As another example, if you use Stan from R, you have to feed it a script in a different language, while your Turing.jl models can be written in normal Julia. There’s really no limit to what you can send through Bayesian inference this way. Additionally, advanced topics like metaprogramming and optimization are always only a few steps away, and interesting lessons about one’s own code or the inner workings of Julia can be learned just by applying a couple of macros such as @code_warntype here and there. A transformation from beginner to expert code sometimes goes only through a couple minor changes like adding @inbounds in strategical places, or minimizing the use of allocations.\nFor example, with Revise.jl and the @edit macro, it’s quite simple to manipulate even Base functions on the fly, and play around with different implementations of Julia’s fundamental building blocks. The multiple dispatch paradigm makes it possible to inject functionality deep into third party code and to connect one’s homegrown implementations with the work of others in a way that I have never seen in Python, R or Matlab. This is not brittle tampering like, e.g., monkeypatching in Python, but allows you to meaningfully extend the available functionality if you want to. Packages are specifically written to be extensible by others, each dispatch presents an opportunity for third parties to hook into. One person might have a small idea, but through Julia’s ability for composition, it can easily become part of something bigger (like the often cited Differential Equations + Measurements + Plot Recipe combo).\nI think Julia’s gentle learning curve and raw processing power are an invitation to domain experts outside of computer science to help write the software their fields need. Personally, it makes me feel more powerful and self-sufficient to work in a dynamic language that can not only give access to other people’s well written packages (written in Julia, but also R, Python and Matlab through RCall.jl, PyCall.jl and MATLAB.jl, respectively). It also allows me to write my own, and not just for toy problems but theoretically scalable even to supercomputers.\nI hope that in the future Julia loses the perception of being a niche language for numerics, which might discourage people who don’t need just that from trying it. Instead, I would frame it as a powerful general programming language that offers something for everyone from beginners to experts and encourages collaboration and code reuse through its extensible multiple dispatch paradigm. If researchers write more algorithms in high-level Julia and not in low-level C++, this could make them more accessible for novices and easier to check for other researchers, because Julia shares the same “pseudo-code” qualities of Python (which doesn’t actually look so clean anymore if everything is prefixed by np.). The Julia community also highly values CI and good test coverage and I hope that such things become more mainstream in the future, because every scientist that works with code can benefit from adopting these best practices.\nI wrote this post because I felt these aspects tend to be under-represented when Julia is discussed. Sometimes, the focus on micro-benchmarks and the resulting exaggerated or one-sided claims of superior performance expectedly cause users of other languages to go into defense mode. That’s not necessary in my opinion. Yes, Python R and Matlab also have amazing fast packages that enable people to do great research. But these languages are also fundamentally limited in how low-level users can reach, and they don’t allow for the same freedom to create beautiful and generic implementations that still harness all available computing power. They don’t allow scientists to bridge the gap from user to creator quite as well. And bridging that gap holds a lot of potential, especially in today’s world where everything is about code."
  }
]